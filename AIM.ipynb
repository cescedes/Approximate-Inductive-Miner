{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.algo.evaluation.replay_fitness import algorithm as fitness_evaluator\n",
    "from pm4py.algo.evaluation.precision import algorithm as precision_evaluator\n",
    "from pm4py.objects.process_tree.obj import ProcessTree, Operator\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApproximateInductiveMiner:\n",
    "    def __init__(self, filter_steps=10):\n",
    "        self.filter_values = [x / filter_steps for x in range(1, filter_steps)]\n",
    "\n",
    "    def filter_event_log(self, log, threshold):\n",
    "        \"\"\"\n",
    "        Dynamically filter activities based on occurrence threshold.\n",
    "        Incorporates adjustment for information loss as per AIM.\n",
    "        \"\"\"\n",
    "        activity_counts = pm4py.get_event_attribute_values(log, \"concept:name\")\n",
    "        max_count = max(activity_counts.values())\n",
    "\n",
    "        filtered_log = []\n",
    "        for trace in log:\n",
    "            valid_trace = all(\n",
    "                activity_counts.get(ev[\"concept:name\"], 0) >= max_count * threshold\n",
    "                for ev in trace\n",
    "            )\n",
    "            if valid_trace:\n",
    "                filtered_log.append(trace)\n",
    "\n",
    "        # Adjust quality for information loss\n",
    "        info_loss_factor = len(filtered_log) / len(log) if log else 1\n",
    "        return filtered_log, info_loss_factor\n",
    "\n",
    "    def calculate_relations(self, log):\n",
    "        \"\"\"\n",
    "        Create a directly-follows matrix for the log.\n",
    "        \"\"\"\n",
    "        activities = list(pm4py.get_event_attribute_values(log, \"concept:name\"))\n",
    "        matrix = np.zeros((len(activities), len(activities)))\n",
    "\n",
    "        for trace in log:\n",
    "            for i in range(len(trace) - 1):\n",
    "                a = activities.index(trace[i][\"concept:name\"])\n",
    "                b = activities.index(trace[i + 1][\"concept:name\"])\n",
    "                matrix[a][b] += 1\n",
    "\n",
    "        return matrix\n",
    "\n",
    "    def estimate_quality(self, operator, clusters, relations, info_loss_factor):\n",
    "        \"\"\"\n",
    "        Operator-specific quality estimation incorporating information loss.\n",
    "        \"\"\"\n",
    "        cluster_0_indices = np.where(clusters == 0)[0]\n",
    "        cluster_1_indices = np.where(clusters == 1)[0]\n",
    "\n",
    "        inter_cluster = relations[np.ix_(cluster_0_indices, cluster_1_indices)].sum()\n",
    "        intra_cluster = relations[np.ix_(cluster_0_indices, cluster_0_indices)].sum() + \\\n",
    "                        relations[np.ix_(cluster_1_indices, cluster_1_indices)].sum()\n",
    "\n",
    "        if operator == \"sequence\":\n",
    "            quality = inter_cluster / (inter_cluster + intra_cluster + 1)\n",
    "        elif operator == \"parallel\":\n",
    "            quality = 2 * inter_cluster * intra_cluster / (inter_cluster ** 2 + intra_cluster ** 2 + 1)\n",
    "        elif operator == \"exclusive\":\n",
    "            quality = 1 / (inter_cluster + intra_cluster + 1)\n",
    "        elif operator == \"loop\":\n",
    "            quality = inter_cluster / (intra_cluster + 1)\n",
    "        else:\n",
    "            quality = 0\n",
    "\n",
    "        return quality * info_loss_factor\n",
    "\n",
    "    def cluster_relations(self, relations, operator):\n",
    "        \"\"\"\n",
    "        Perform clustering using KMeans and operator-specific distance measures.\n",
    "        \"\"\"\n",
    "        if relations.shape[0] < 2:\n",
    "            return np.zeros(relations.shape[0], dtype=int)\n",
    "\n",
    "        kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "        clusters = kmeans.fit_predict(relations)\n",
    "\n",
    "        return clusters\n",
    "\n",
    "    def find_best_cut(self, log):\n",
    "        \"\"\"\n",
    "        Evaluate cuts dynamically over filter parameters.\n",
    "        \"\"\"\n",
    "        best_cut = None\n",
    "        best_quality = -float('inf')\n",
    "\n",
    "        for filter_value in self.filter_values:\n",
    "            filtered_log, info_loss_factor = self.filter_event_log(log, filter_value)\n",
    "            if not filtered_log:\n",
    "                continue\n",
    "\n",
    "            relations = self.calculate_relations(filtered_log)\n",
    "            if relations.size == 0:\n",
    "                continue\n",
    "\n",
    "            for operator in [\"sequence\", \"parallel\", \"exclusive\", \"loop\"]:\n",
    "                clusters = self.cluster_relations(relations, operator)\n",
    "                if len(set(clusters)) < 2:\n",
    "                    continue\n",
    "\n",
    "                quality = self.estimate_quality(operator, clusters, relations, info_loss_factor)\n",
    "                if quality > best_quality:\n",
    "                    best_cut = (operator, clusters)\n",
    "                    best_quality = quality\n",
    "\n",
    "        return best_cut\n",
    "\n",
    "    def split_log(self, log, cut):\n",
    "        \"\"\"\n",
    "        Split log into sub-logs based on clustering results.\n",
    "        \"\"\"\n",
    "        left, right = [], []\n",
    "        operator, clusters = cut\n",
    "\n",
    "        activity_names = list(pm4py.get_event_attribute_values(log, \"concept:name\"))\n",
    "        activity_to_cluster = {activity_names[i]: clusters[i] for i in range(len(clusters))}\n",
    "\n",
    "        for trace in log:\n",
    "            left_trace, right_trace = [], []\n",
    "            for ev in trace:\n",
    "                cluster_index = activity_to_cluster.get(ev[\"concept:name\"], -1)\n",
    "                if cluster_index == 0:\n",
    "                    left_trace.append(ev)\n",
    "                elif cluster_index == 1:\n",
    "                    right_trace.append(ev)\n",
    "\n",
    "            if left_trace:\n",
    "                left.append(left_trace)\n",
    "            if right_trace:\n",
    "                right.append(right_trace)\n",
    "\n",
    "        return left, right\n",
    "\n",
    "    def discover_process_tree(self, log):\n",
    "        base_case = self.check_base_case(log)\n",
    "        if base_case:\n",
    "            return base_case\n",
    "\n",
    "        cut = self.find_best_cut(log)\n",
    "        if cut:\n",
    "            left_log, right_log = self.split_log(log, cut)\n",
    "            if not left_log or not right_log:\n",
    "                return self.create_flower_model(log)\n",
    "\n",
    "            left_tree = self.discover_process_tree(left_log)\n",
    "            right_tree = self.discover_process_tree(right_log)\n",
    "\n",
    "            root = ProcessTree(operator=self.get_operator(cut[0]))\n",
    "            root.children.append(left_tree)\n",
    "            root.children.append(right_tree)\n",
    "            return root\n",
    "\n",
    "        return self.create_flower_model(log)\n",
    "\n",
    "    def check_base_case(self, log):\n",
    "        if not log:\n",
    "            return ProcessTree(operator=Operator.TAU)\n",
    "\n",
    "        activities = set(ev[\"concept:name\"] for trace in log for ev in trace)\n",
    "        if len(activities) == 1:\n",
    "            activity = next(iter(activities))\n",
    "            return ProcessTree(label=activity)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def create_flower_model(self, log):\n",
    "        \"\"\"\n",
    "        Create a flower model as a fallback for unsplittable logs.\n",
    "        \"\"\"\n",
    "        activities = set(ev[\"concept:name\"] for trace in log for ev in trace)\n",
    "        root = ProcessTree(operator=Operator.PARALLEL)\n",
    "        for activity in activities:\n",
    "            root.children.append(ProcessTree(label=activity))\n",
    "        return root\n",
    "\n",
    "    def get_operator(self, operator_str):\n",
    "        \"\"\"\n",
    "        Map string operator to ProcessTree operator.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"sequence\": Operator.SEQUENCE,\n",
    "            \"exclusive\": Operator.XOR,\n",
    "            \"parallel\": Operator.PARALLEL,\n",
    "            \"loop\": Operator.LOOP\n",
    "        }.get(operator_str, Operator.SEQUENCE)\n",
    "\n",
    "\n",
    "    def evaluate_model(self, log, process_tree):\n",
    "        try:\n",
    "            net, initial_marking, final_marking = pm4py.objects.conversion.process_tree.converter.apply(process_tree)\n",
    "\n",
    "            fitness = fitness_evaluator.apply(log, net, initial_marking, final_marking)\n",
    "            precision = precision_evaluator.apply(log, net, initial_marking, final_marking)\n",
    "            size = len(str(process_tree))\n",
    "\n",
    "            return {\n",
    "                \"fitness\": fitness,\n",
    "                \"precision\": precision,\n",
    "                \"size\": size\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(\"Error during evaluation:\", e)\n",
    "            return {\n",
    "                \"fitness\": None,\n",
    "                \"precision\": None,\n",
    "                \"size\": None\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6875cb4a0f9646869677e202ab92d16e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/1199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+( +( *( '01_HOOFD_010', '01_HOOFD_011' ), +( +( *( '02_DRZ_010', '01_HOOFD_110_0' ), +( '01_HOOFD_015', *( '01_HOOFD_020', '01_HOOFD_061' ) ) ), '09_AH_I_010' ) ), '04_BPT_005' )\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0dc60d296d4085b1df08f0254a3010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aligning log, completed variants ::   0%|          | 0/1170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45433749fc6c480f8d910d9752ad1212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "computing precision with alignments, completed variants ::   0%|          | 0/38934 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: {'fitness': {'percFitTraces': 0.0, 'averageFitness': 0.23241735241366046, 'percentage_of_fitting_traces': 0.0, 'average_trace_fitness': 0.23241735241366046, 'log_fitness': 0.2056513218901047}, 'precision': 0.42448450825866346, 'size': 179}\n"
     ]
    }
   ],
   "source": [
    "log = xes_importer.apply(\"BPIC15_1.xes\")\n",
    "aim = ApproximateInductiveMiner()\n",
    "process_tree = aim.discover_process_tree(log)\n",
    "print(process_tree)\n",
    "evaluation = aim.evaluate_model(log, process_tree)\n",
    "print(\"Evaluation:\", evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BI2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
